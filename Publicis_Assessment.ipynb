{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.12\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "print(platform.python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "## Load the training dataset as separate collections (collection named after their topic name) into a mongo database called stack.  Each discussion is composed of a question and its answers.  You are only allowed to use the \"title\" and \"body\" fields of each discussion - of both the question and its answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "\n",
    "#Connecting to a mongo database running on localhost, port 2707 \n",
    "client = MongoClient('localhost', 27017)\n",
    "db = client.stack\n",
    "\n",
    "#Load the data from collections into a list of dictionaries\n",
    "astronomy_list = list(db.astronomy_posts.find())\n",
    "pets_list = list(db.pets_posts.find())\n",
    "beer_list = list(db.beer_posts.find())\n",
    "outdoors_list = list(db.outdoors_posts.find())\n",
    "aviation_list = list(db.aviation_posts.find())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#First, we need to extract title and body of each question and answer\n",
    "\n",
    "#astronomy data\n",
    "astronomy_qst_titless = \"\"\n",
    "astronomy_qst_body = \"\"\n",
    "astronomy_ans_body = \"\"\n",
    "astronomy_all = \"\"\n",
    "\n",
    "for doc in astronomy_list: astronomy_qst_titless = astronomy_qst_titless + \" \" + doc['title']\n",
    "for doc in astronomy_list: astronomy_qst_body = astronomy_qst_body + \" \" + doc['body']\n",
    "for doc in astronomy_list:\n",
    "    for ans in doc[\"answers\"]:\n",
    "        astronomy_ans_body = astronomy_ans_body + \" \" + ans['body']\n",
    "\n",
    "astronomy_all = astronomy_qst_titless + \" \" + astronomy_qst_body + \" \" + astronomy_ans_body\n",
    "\n",
    "\n",
    "#pets data\n",
    "pets_qst_titless = \"\"\n",
    "pets_qst_body = \"\"\n",
    "pets_ans_body = \"\"\n",
    "pets_all = \"\"\n",
    "\n",
    "for doc in pets_list: pets_qst_titless = pets_qst_titless + \" \" + doc['title']\n",
    "for doc in pets_list: pets_qst_body = pets_qst_body + \" \" + doc['body']\n",
    "for doc in pets_list:\n",
    "    for ans in doc[\"answers\"]:\n",
    "        pets_ans_body = pets_ans_body + \" \" + ans['body']\n",
    "\n",
    "pets_all = pets_qst_titless + \" \" + pets_qst_body + \" \" + pets_ans_body\n",
    "\n",
    "#beer data\n",
    "beer_qst_titless = \"\"\n",
    "beer_qst_body = \"\"\n",
    "beer_ans_body = \"\"\n",
    "beer_all = \"\"\n",
    "\n",
    "for doc in beer_list: beer_qst_titless = beer_qst_titless + \" \" + doc['title']\n",
    "for doc in beer_list: beer_qst_body = beer_qst_body + \" \" + doc['body']\n",
    "for doc in beer_list:\n",
    "    for ans in doc[\"answers\"]:\n",
    "        beer_ans_body = beer_ans_body + \" \" + ans['body']\n",
    "\n",
    "beer_all = beer_qst_titless + \" \" + beer_qst_body + \" \" + beer_ans_body\n",
    "\n",
    "#Outdoors data\n",
    "outdoors_qst_titless = \"\"\n",
    "outdoors_qst_body = \"\"\n",
    "outdoors_ans_body = \"\"\n",
    "outdoors_all = \"\"\n",
    "\n",
    "for doc in outdoors_list: outdoors_qst_titless = outdoors_qst_titless + \" \" + doc['title']\n",
    "for doc in outdoors_list: outdoors_qst_body = outdoors_qst_body + \" \" + doc['body']\n",
    "for doc in outdoors_list:\n",
    "    for ans in doc[\"answers\"]:\n",
    "        outdoors_ans_body = outdoors_ans_body + \" \" + ans['body']\n",
    "\n",
    "outdoors_all = outdoors_qst_titless + \" \" + outdoors_qst_body + \" \" + outdoors_ans_body\n",
    "\n",
    "#Aviation data\n",
    "aviation_qst_titless = \"\"\n",
    "aviation_qst_body = \"\"\n",
    "aviation_ans_body = \"\"\n",
    "aviation_all = \"\"\n",
    "\n",
    "for doc in aviation_list: aviation_qst_titless = aviation_qst_titless + \" \" + doc['title']\n",
    "for doc in aviation_list: aviation_qst_body = aviation_qst_body + \" \" + doc['body']\n",
    "for doc in aviation_list:\n",
    "    for ans in doc[\"answers\"]:\n",
    "        aviation_ans_body = aviation_ans_body + \" \" + ans['body']\n",
    "\n",
    "aviation_all = aviation_qst_titless + \" \" + aviation_qst_body + \" \" + aviation_ans_body\n",
    "\n",
    "whole_dataset = astronomy_all + \" \" + pets_all + \" \" + beer_all + \" \" + outdoors_all + \" \" + aviation_all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'how', u'are', u'the', u'compositional', u'components', u'of', u'exoplanet', u'atmospheres', u'differentiated', u'amateur']\n"
     ]
    }
   ],
   "source": [
    "#Before we proceed to Part 2, we need to clean the data. First, we tokenize our topic strings, remove all words that are not \n",
    "#alpha-numeric, transforming all words into lower case, and removing any punctuation marks. \n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#astronomy\n",
    "astronomy_all_tokens = word_tokenize(astronomy_all)\n",
    "astronomy_all_tokens_punc = [word for word in astronomy_all_tokens if word.isalpha()]\n",
    "astronomy_all_tokens_low = [x.lower() for x in astronomy_all_tokens_punc]\n",
    "\n",
    "#pets\n",
    "pets_all_tokens = word_tokenize(pets_all)\n",
    "pets_all_tokens_punc = [word for word in pets_all_tokens if word.isalpha()]\n",
    "pets_all_tokens_low = [x.lower() for x in pets_all_tokens_punc]\n",
    "\n",
    "#beer\n",
    "beer_all_tokens = word_tokenize(beer_all)\n",
    "beer_all_tokens_punc = [word for word in beer_all_tokens if word.isalpha()]\n",
    "beer_all_tokens_low = [x.lower() for x in beer_all_tokens_punc]\n",
    "\n",
    "#aviation\n",
    "aviation_all_tokens = word_tokenize(aviation_all)\n",
    "aviation_all_tokens_punc = [word for word in aviation_all_tokens if word.isalpha()]\n",
    "aviation_all_tokens_low = [x.lower() for x in aviation_all_tokens_punc]\n",
    "\n",
    "#outdoors\n",
    "outdoors_all_tokens = word_tokenize(outdoors_all)\n",
    "outdoors_all_tokens_punc = [word for word in outdoors_all_tokens if word.isalpha()]\n",
    "outdoors_all_tokens_low = [x.lower() for x in outdoors_all_tokens_punc]\n",
    "\n",
    "#Entire dataset\n",
    "whole_dataset_tokens = word_tokenize(whole_dataset)\n",
    "whole_dataset_tokens_punc = [word for word in whole_dataset_tokens if word.isalpha()]\n",
    "whole_dataset_tokens_low = [x.lower() for x in whole_dataset_tokens_punc]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'compositional', u'components', u'exoplanet', u'atmospheres', u'differentiated', u'amateur', u'observing', u'targets', u'binary', u'star', u'systems', u'calculate', u'inclination', u'object', u'amateur', u'telescope', u'ca', u'light', u'escape', u'black', u'hole', u'astronomers', u'researching', u'trying', u'find', u'signs', u'worm', u'holes', u'extreme', u'weather', u'found', u'another', u'planet', u'someone', u'explain', u'simple', u'terms', u'current', u'accepted', u'theory', u'venus', u'slow', u'retrograde', u'rotation', u'information', u'leave', u'black', u'hole', u'one', u'side']\n",
      "\n",
      "[u'citra', u'hop', u'differ', u'hops', u'reduced', u'alcoholic', u'beer', u'made', u'certain', u'types', u'beer', u'get', u'drunk', u'quickly', u'first', u'beer', u'ever', u'brewed', u'mull', u'beer', u'temperature', u'serve', u'beer', u'difference', u'ale', u'lager', u'average', u'brewing', u'time', u'craft', u'beer', u'factors', u'affect', u'carbonation', u'level', u'beer', u'ipas', u'cause', u'worse', u'hangovers', u'bottled', u'beer', u'taste', u'good', u'draught', u'beer', u'seem', u'pee', u'beer', u'drink']\n",
      "\n",
      "[u'sightsee', u'class', u'bravo', u'airspace', u'controller', u'using', u'word', u'request', u'crossing', u'runway', u'switching', u'frequencies', u'collaring', u'circuit', u'breaker', u'considered', u'deactivation', u'faa', u'single', u'engine', u'aircraft', u'wanting', u'enter', u'stall', u'bystander', u'ground', u'see', u'aircraft', u'appears', u'failing', u'log', u'flight', u'time', u'passenger', u'standards', u'flew', u'class', u'b', u'airspace', u'without', u'clearance', u'sport', u'pilot', u'get', u'private', u'pilot', u'certificate', u'estimate', u'minimum', u'runway']\n",
      "\n",
      "[u'treat', u'hot', u'spots', u'blisters', u'moleskin', u'alps', u'safe', u'drink', u'water', u'without', u'filtering', u'legal', u'camp', u'private', u'property', u'russia', u'sail', u'raft', u'european', u'river', u'commercial', u'traffic', u'critical', u'dimensions', u'safe', u'safest', u'way', u'purify', u'water', u'prevent', u'altitude', u'sickness', u'navigate', u'without', u'compass', u'gps', u'difference', u'external', u'packs', u'good', u'tips', u'techniques', u'packing', u'backpack', u'buying', u'backpack', u'pay', u'attention', u'treat', u'poison']\n",
      "\n",
      "[u'causes', u'dog', u'lunge', u'unknown', u'child', u'owner', u'respond', u'walk', u'small', u'dog', u'afraid', u'loud', u'noises', u'urban', u'area', u'refresh', u'overheated', u'cat', u'prevent', u'overheating', u'first', u'place', u'best', u'way', u'toilet', u'train', u'puppy', u'ensure', u'ferret', u'longevity', u'corn', u'based', u'food', u'bad', u'dog', u'cat', u'reacts', u'randomly', u'tail', u'enters', u'frenzy', u'cats', u'safely', u'eat', u'raw', u'meat', u'best', u'way', u'heal', u'scab']\n",
      "\n",
      "[u'compositional', u'components', u'exoplanet', u'atmospheres', u'differentiated', u'amateur', u'observing', u'targets', u'binary', u'star', u'systems', u'calculate', u'inclination', u'object', u'amateur', u'telescope', u'ca', u'light', u'escape', u'black']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Next, we need to remove all stop words from our dataset that do not add much information. Note that I appended\n",
    "# the default set of stop words with a few more that were occuring frequently in our data\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add(u'use')\n",
    "stop_words.add(u'would')\n",
    "stop_words.add(u'like')\n",
    "stop_words.add(u'also')\n",
    "stop_words.add(u'could')\n",
    "\n",
    "\n",
    "astronomy_all_tokens_stop = [w for w in astronomy_all_tokens_low if not w in stop_words]\n",
    "outdoors_all_tokens_stop = [w for w in outdoors_all_tokens_low if not w in stop_words]\n",
    "pets_all_tokens_stop = [w for w in pets_all_tokens_low if not w in stop_words]\n",
    "aviation_all_tokens_stop = [w for w in aviation_all_tokens_low if not w in stop_words]\n",
    "beer_all_tokens_stop = [w for w in beer_all_tokens_low if not w in stop_words]\n",
    "whole_dataset_tokens_stop = [w for w in whole_dataset_tokens_low if not w in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'composit', u'compon', u'exoplanet', u'atmospher', u'differenti', u'amateur', u'observ', u'target', u'binari', u'star', u'system', u'calcul', u'inclin', u'object', u'amateur', u'telescop', u'ca', u'light', u'escap', u'black', u'hole', u'astronom', u'research', u'tri', u'find', u'sign', u'worm', u'hole', u'extrem', u'weather', u'found', u'anoth', u'planet', u'someon', u'explain', u'simpl', u'term', u'current', u'accept', u'theori', u'venu', u'slow', u'retrograd', u'rotat', u'inform', u'leav', u'black', u'hole', u'one', u'side']\n",
      "\n",
      "[u'citra', u'hop', u'differ', u'hop', u'reduc', u'alcohol', u'beer', u'made', u'certain', u'type', u'beer', u'get', u'drunk', u'quickli', u'first', u'beer', u'ever', u'brew', u'mull', u'beer', u'temperatur', u'serv', u'beer', u'differ', u'ale', u'lager', u'averag', u'brew', u'time', u'craft', u'beer', u'factor', u'affect', u'carbon', u'level', u'beer', u'ipa', u'caus', u'wors', u'hangov', u'bottl', u'beer', u'tast', u'good', u'draught', u'beer', u'seem', u'pee', u'beer', u'drink']\n",
      "\n",
      "[u'sightse', u'class', u'bravo', u'airspac', u'control', u'use', u'word', u'request', u'cross', u'runway', u'switch', u'frequenc', u'collar', u'circuit', u'breaker', u'consid', u'deactiv', u'faa', u'singl', u'engin', u'aircraft', u'want', u'enter', u'stall', u'bystand', u'ground', u'see', u'aircraft', u'appear', u'fail', u'log', u'flight', u'time', u'passeng', u'standard', u'flew', u'class', u'b', u'airspac', u'without', u'clearanc', u'sport', u'pilot', u'get', u'privat', u'pilot', u'certif', u'estim', u'minimum', u'runway']\n",
      "\n",
      "[u'treat', u'hot', u'spot', u'blister', u'moleskin', u'alp', u'safe', u'drink', u'water', u'without', u'filter', u'legal', u'camp', u'privat', u'properti', u'russia', u'sail', u'raft', u'european', u'river', u'commerci', u'traffic', u'critic', u'dimens', u'safe', u'safest', u'way', u'purifi', u'water', u'prevent', u'altitud', u'sick', u'navig', u'without', u'compass', u'gp', u'differ', u'extern', u'pack', u'good', u'tip', u'techniqu', u'pack', u'backpack', u'buy', u'backpack', u'pay', u'attent', u'treat', u'poison']\n",
      "\n",
      "[u'caus', u'dog', u'lung', u'unknown', u'child', u'owner', u'respond', u'walk', u'small', u'dog', u'afraid', u'loud', u'nois', u'urban', u'area', u'refresh', u'overh', u'cat', u'prevent', u'overh', u'first', u'place', u'best', u'way', u'toilet', u'train', u'puppi', u'ensur', u'ferret', u'longev', u'corn', u'base', u'food', u'bad', u'dog', u'cat', u'react', u'randomli', u'tail', u'enter', u'frenzi', u'cat', u'safe', u'eat', u'raw', u'meat', u'best', u'way', u'heal', u'scab']\n",
      "\n",
      "[u'composit', u'compon', u'exoplanet', u'atmospher', u'differenti', u'amateur', u'observ', u'target', u'binari', u'star', u'system', u'calcul', u'inclin', u'object', u'amateur', u'telescop', u'ca', u'light', u'escap', u'black', u'hole', u'astronom', u'research', u'tri', u'find', u'sign', u'worm', u'hole', u'extrem', u'weather', u'found', u'anoth', u'planet', u'someon', u'explain', u'simpl', u'term', u'current', u'accept', u'theori', u'venu', u'slow', u'retrograd', u'rotat', u'inform', u'leav', u'black', u'hole', u'one', u'side']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Next, we need to \"stem\" our dataset in order to convert each word to it's probably root. After this step, our data is \"clean\"\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "astronomy_clean = [porter.stem(word) for word in astronomy_all_tokens_stop]\n",
    "beer_clean = [porter.stem(word) for word in beer_all_tokens_stop]\n",
    "pets_clean = [porter.stem(word) for word in pets_all_tokens_stop]\n",
    "outdoors_clean = [porter.stem(word) for word in outdoors_all_tokens_stop]\n",
    "aviation_clean = [porter.stem(word) for word in aviation_all_tokens_stop]\n",
    "whole_dataset_clean = [porter.stem(word) for word in whole_dataset_tokens_stop]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "## 2 Find the 1000 most common words in the entire dataset. Ignore case, plurality, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "#In this step, we utilize Counter from collections library and output 1000 most frequent words for each topic\n",
    "\n",
    "astronomy_counter = Counter(astronomy_clean)\n",
    "beer_counter = Counter(beer_clean)\n",
    "pets_counter = Counter(pets_clean)\n",
    "aviation_counter = Counter(aviation_clean)\n",
    "outdoors_counter = Counter(outdoors_clean)\n",
    "#whole_dataset_counter = Counter(whole_dataset_clean)\n",
    "\n",
    "\n",
    "#print(astronomy_counter.most_common(1000))\n",
    "#print(\"\")\n",
    "#print(beer_counter.most_common(1000))\n",
    "#print(\"\")\n",
    "#print(pets_counter.most_common(1000))\n",
    "#print(\"\")\n",
    "#print(aviation_counter.most_common(1000))\n",
    "#print(\"\")\n",
    "#print(outdoors_counter.most_common(1000))\n",
    "#print(\"\")\n",
    "#print(whole_dataset_counter.most_common(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3\n",
    "## Create a term document matrix, tdm, whose (i,j)-th entry is the number of occurrences of word i in document j."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "textmining.TermDocumentMatrix"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textmining\n",
    "\n",
    "#We utilize textmining package to create a Term Document Matrix. Our TDM is rather large, however, there is an option to output into a file\n",
    "astronomy_clean_string = ' '.join(map(str, astronomy_clean))\n",
    "pets_clean_string = ' '.join(map(str, pets_clean))\n",
    "outdoors_clean_string = ' '.join(map(str, outdoors_clean))\n",
    "beer_clean_string = ' '.join(map(str, beer_clean))\n",
    "aviation_clean_string = ' '.join(map(str, aviation_clean))\n",
    "\n",
    "tdm = textmining.TermDocumentMatrix()\n",
    "\n",
    "tdm.add_doc(astronomy_clean_string)\n",
    "tdm.add_doc(pets_clean_string)\n",
    "tdm.add_doc(aviation_clean_string)\n",
    "tdm.add_doc(outdoors_clean_string)\n",
    "tdm.add_doc(beer_clean_string)\n",
    "\n",
    "#for row in tdm.rows(cutoff=1):\n",
    "#    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 \n",
    "## Perform dimension reduction (i.e. PCA) on the tdm and retain 95% variability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -30.99415733,  -60.02389633, -103.48850733,  -78.115669  ],\n",
       "       [  29.49840305,  -98.20321704,  126.29908665,  -20.3881255 ],\n",
       "       [-136.70841335,  111.61243245,   41.57290327,   -2.66318294],\n",
       "       [ 151.88335966,  102.27226834,  -12.86830141,   -4.83146211],\n",
       "       [ -13.67919202,  -55.65758742,  -51.51518118,  105.99843955]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#In order to reduce the number of dimensions in our TDM, we utilize PCA from sklearn library. Before we do that, we need to \n",
    "#stardardize the data using StandardScaler from the same package.\n",
    "\n",
    "#convert textmining.TermDocumentMatrix to a list to feed into PCA\n",
    "tdm_list = [] \n",
    "\n",
    "for row in tdm.rows(cutoff=1):\n",
    "    tdm_list.append(row)\n",
    "\n",
    "#normalize (0 mean, 1 std) the data and save into pandas dataframe to prepare for PCA\n",
    "df_tdm_std = pd.DataFrame(StandardScaler().fit_transform(tdm_list[1:]), columns = tdm_list[0]) \n",
    "\n",
    "\n",
    "pca = PCA(n_components= 0.95, svd_solver='full') #what is this? why svd is full?\n",
    "\n",
    "x = pca.fit_transform(df_tdm_std)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note that there were numerious steps that we had to perform to clean the data above. There was a lot of repetative code, which\n",
    "# is a bad programming style and inefficient. Hence, we create a helper function to address this. We will utilize this function below\n",
    "\n",
    "def post_cleaner(post):\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    from nltk.corpus import stopwords\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.add(u'use')\n",
    "    stop_words.add(u'would')\n",
    "    stop_words.add(u'like')\n",
    "    stop_words.add(u'also')\n",
    "    stop_words.add(u'could')\n",
    "    \n",
    "    post_tokens = word_tokenize(post)\n",
    "    post_tokens_punc = [word for word in post_tokens if word.isalpha()]\n",
    "    post_tokens_low = [x.lower() for x in post_tokens_punc]\n",
    "    post_tokens_stop = [w for w in post_tokens_low if not w in stop_words]\n",
    "    post_tokens_stem = [porter.stem(word) for word in post_tokens_stop]\n",
    "    post_clean = \" \".join(post_tokens_stem)\n",
    "    \n",
    "    return post_clean;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "## Using algorithm(s) of your choice, build a classifier whose labels are the 5 topic names\n",
    "### Prior to training, set aside 500 random discussions from all five files as a hold-out test set. Use the JSON file names as topic tags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "astronomy_qst_titl_bd = []\n",
    "aviation_qst_titl_bd = []\n",
    "pets_qst_titl_bd = []\n",
    "outdoors_qst_titl_bd = []\n",
    "beer_qst_titl_bd = []\n",
    "aviation_set_clean = []\n",
    "astronomy_set_clean = []\n",
    "outdoors_set_clean = []\n",
    "pets_set_clean = []\n",
    "beer_set_clean = []\n",
    "train_set = []\n",
    "train_labels = []\n",
    "\n",
    "for post in astronomy_list:\n",
    "    astronomy_qst_titl_bd.append(\"%s  %s  %s  \" % \n",
    "                                 (post['title'], post['body'], (\" \".join(map(str, (ans['body'] for ans in post['answers']))))))\n",
    "\n",
    "for post in pets_list:\n",
    "    pets_qst_titl_bd.append(\"%s  %s  %s  \" % \n",
    "                                 (post['title'], post['body'], (\" \".join(map(str, (ans['body'] for ans in post['answers']))))))\n",
    "\n",
    "for post in outdoors_list:\n",
    "    outdoors_qst_titl_bd.append(\"%s  %s  %s  \" % \n",
    "                                 (post['title'], post['body'], (\" \".join(map(str, (ans['body'] for ans in post['answers']))))))\n",
    "\n",
    "for post in beer_list:\n",
    "    beer_qst_titl_bd.append(\"%s  %s  %s  \" % \n",
    "                                 (post['title'], post['body'], (\" \".join(map(str, (ans['body'] for ans in post['answers']))))))\n",
    "\n",
    "for post in aviation_list:\n",
    "    aviation_qst_titl_bd.append(\"%s  %s  %s  \" % \n",
    "                                 (post['title'], post['body'], (\" \".join(map(str, (ans['body'] for ans in post['answers']))))))\n",
    "\n",
    "# We clean our data using a clear_post function defined earlier\n",
    "    \n",
    "for post in aviation_qst_titl_bd:\n",
    "    aviation_set_clean.append(post_cleaner(post))\n",
    "    \n",
    "for post in astronomy_qst_titl_bd:\n",
    "    astronomy_set_clean.append(post_cleaner(post))\n",
    "   \n",
    "for post in outdoors_qst_titl_bd:\n",
    "    outdoors_set_clean.append(post_cleaner(post))\n",
    "    \n",
    "for post in pets_qst_titl_bd:\n",
    "    pets_set_clean.append(post_cleaner(post))\n",
    "    \n",
    "for post in beer_qst_titl_bd:\n",
    "    beer_set_clean.append(post_cleaner(post))\n",
    "\n",
    "# Next, we split our dataset into training and hold-out test sets \n",
    "\n",
    "aviation_train, aviation_test = train_test_split(aviation_set_clean, test_size=100, random_state=42)\n",
    "beer_train, beer_test = train_test_split(beer_set_clean, test_size=100, random_state=42)\n",
    "astronomy_train, astronomy_test = train_test_split(astronomy_set_clean, test_size=100, random_state=42)\n",
    "outdoors_train, outdoors_test = train_test_split(outdoors_set_clean, test_size=100, random_state=42)\n",
    "pets_train, pets_test = train_test_split(pets_set_clean, test_size=100, random_state=42)\n",
    "\n",
    "aviation_labels = ['aviation'] * len(aviation_train)    \n",
    "beer_labels = ['beer'] * len(beer_train)  \n",
    "astronomy_labels = ['astronomy'] * len(astronomy_train)\n",
    "outdoors_labels = ['outdoors'] * len(outdoors_train)\n",
    "    \n",
    "train_set.extend(aviation_train)\n",
    "train_set.extend(beer_train)\n",
    "train_set.extend(astronomy_train)\n",
    "train_set.extend(outdoors_train)\n",
    "train_set.extend(pets_train)\n",
    "    \n",
    "train_labels.extend(aviation_labels)\n",
    "train_labels.extend(beer_labels)\n",
    "train_labels.extend(astronomy_labels)\n",
    "train_labels.extend(outdoors_labels)\n",
    "train_labels.extend(pets_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "\n",
    "### Based on the training set, build a classifier to classify an un-labeled document into one of the five topics.  Choose any tuning parameters based on 10-fold cross-validation.  Report the performance of the full validated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best parameters: ', {'vect__ngram_range': (1, 2), 'tfidf__use_idf': True, 'clf__alpha': 0.001})\n",
      "('Best score: ', 0.98141194141945176)\n"
     ]
    }
   ],
   "source": [
    "# First, we run Naive Bayes classifier. It's always a good benchmark\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "#In avoid repetative data manipulations, we utilize Pipeline\n",
    "NB_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}\n",
    "\n",
    "#We run 10-fold cross validation to select the model based on the defined parameters above\n",
    "NB_gs_clf = GridSearchCV(NB_clf, parameters, cv=10, n_jobs=-1)\n",
    "NB_gs_model = NB_gs_clf.fit(train_set, train_labels)\n",
    "print(\"Best parameters: \", NB_gs_clf.best_params_)\n",
    "print(\"Best score: \", NB_gs_clf.best_score_)\n",
    "\n",
    "NB_pets_predicted = NB_gs_clf.predict(pets_test)\n",
    "NB_beer_predicted = NB_gs_clf.predict(beer_test)\n",
    "NB_astronomy_predicted = NB_gs_clf.predict(astronomy_test)\n",
    "NB_outdoors_predicted = NB_gs_clf.predict(outdoors_test)\n",
    "NB_aviation_predicted = NB_gs_clf.predict(aviation_test)\n",
    "\n",
    "NB_pets_predicted_prob = NB_gs_clf.predict_proba(pets_test)\n",
    "NB_beer_predicted_prob = NB_gs_clf.predict_proba(beer_test)\n",
    "NB_astronomy_predicted_prob = NB_gs_clf.predict_proba(astronomy_test)\n",
    "NB_outdoors_predicted_prob = NB_gs_clf.predict_proba(outdoors_test)\n",
    "NB_aviation_predicted_prob = NB_gs_clf.predict_proba(aviation_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5\n",
    "\n",
    "### Test your classifier using the hold-out test set.  Report the performance of the test run (remember you know the true labels of the hold out test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Pets:  1.0\n",
      "Accuracy score for Beer:  0.97\n",
      "Accuracy score for Outdoors:  0.98\n",
      "Accuracy score for Aviation:  1.0\n",
      "Accuracy score for Astronomy:  0.98\n",
      "\n",
      "\n",
      "\n",
      "Micro f1 score for Pets:  1.0\n",
      "Micro f1 score for Beer:  0.97\n",
      "Micro f1 score for Outdoors:  0.98\n",
      "Micro f1 score for Aviation:  1.0\n",
      "Micro f1 score for Astronomy:  0.98\n",
      "\n",
      "\n",
      "\n",
      "Weighted f1 score for Pets:  1.0\n",
      "Weighted f1 score for Beer:  0.955228426396\n",
      "Weighted f1 score for Outdoors:  0.970101010101\n",
      "Weighted f1 score for Aviation:  1.0\n",
      "Weighted f1 score for Astronomy:  0.970101010101\n",
      "\n",
      "\n",
      "\n",
      "Classificaiton Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       pets       1.00      0.98      0.99       100\n",
      "       beer       0.99      1.00      1.00       100\n",
      "   outdoors       1.00      0.97      0.98       100\n",
      "   aviation       0.95      0.98      0.97       100\n",
      "  astronomy       0.99      1.00      1.00       100\n",
      "\n",
      "avg / total       0.99      0.99      0.99       500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[100   0   0   0   0]\n",
      " [  0  97   3   0   0]\n",
      " [  1   0  98   1   0]\n",
      " [  0   0   0 100   0]\n",
      " [  0   0   2   0  98]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "NB_all_predicted = []\n",
    "NB_test_labels = []\n",
    "\n",
    "NB_all_predicted.extend(NB_astronomy_predicted)\n",
    "NB_all_predicted.extend(NB_beer_predicted)\n",
    "NB_all_predicted.extend(NB_pets_predicted)\n",
    "NB_all_predicted.extend(NB_outdoors_predicted)\n",
    "NB_all_predicted.extend(NB_aviation_predicted)\n",
    "\n",
    "NB_pets_test_label = ['pets']*len(NB_pets_predicted)\n",
    "NB_beer_test_label = ['beer']*len(NB_beer_predicted)\n",
    "NB_outdoors_test_label = ['outdoors']*len(NB_outdoors_predicted)\n",
    "NB_astronomy_test_label = ['astronomy']*len(NB_astronomy_predicted)\n",
    "NB_aviation_test_label = ['aviation']*len(NB_aviation_predicted)\n",
    "\n",
    "NB_test_labels.extend(NB_astronomy_test_label)\n",
    "NB_test_labels.extend(NB_beer_test_label)\n",
    "NB_test_labels.extend(NB_pets_test_label)\n",
    "NB_test_labels.extend(NB_outdoors_test_label)\n",
    "NB_test_labels.extend(NB_aviation_test_label)\n",
    "\n",
    "\n",
    "#Evaluate performance of the model on the hold-out set\n",
    "\n",
    "#Accuracy\n",
    "print(\"%s %s\" % (\"Accuracy score for Pets: \", metrics.accuracy_score(NB_pets_predicted, NB_pets_test_label)))\n",
    "print(\"%s %s\" % (\"Accuracy score for Beer: \", metrics.accuracy_score(NB_beer_predicted, NB_beer_test_label)))\n",
    "print(\"%s %s\" % (\"Accuracy score for Outdoors: \", metrics.accuracy_score(NB_outdoors_predicted, NB_outdoors_test_label)))\n",
    "print(\"%s %s\" % (\"Accuracy score for Aviation: \", metrics.accuracy_score(NB_aviation_predicted, NB_aviation_test_label)))\n",
    "print(\"%s %s\" % (\"Accuracy score for Astronomy: \", metrics.accuracy_score(NB_astronomy_predicted, NB_astronomy_test_label)))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "# micro f1 scores\n",
    "print(\"%s %s\" % (\"Micro f1 score for Pets: \", metrics.f1_score(NB_pets_predicted, NB_pets_test_label, average = 'micro')))\n",
    "print(\"%s %s\" % (\"Micro f1 score for Beer: \", metrics.f1_score(NB_beer_predicted, NB_beer_test_label, average = 'micro')))\n",
    "print(\"%s %s\" % (\"Micro f1 score for Outdoors: \", metrics.f1_score(NB_outdoors_predicted, NB_outdoors_test_label, average = 'micro')))\n",
    "print(\"%s %s\" % (\"Micro f1 score for Aviation: \", metrics.f1_score(NB_aviation_predicted, NB_aviation_test_label, average = 'micro')))\n",
    "print(\"%s %s\" % (\"Micro f1 score for Astronomy: \", metrics.f1_score(NB_astronomy_predicted, NB_astronomy_test_label, average = 'micro')))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "# macro f1 scores\n",
    "print(\"%s %s\" % (\"Weighted f1 score for Pets: \", metrics.f1_score(NB_pets_predicted, NB_pets_test_label, average = 'weighted')))\n",
    "print(\"%s %s\" % (\"Weighted f1 score for Beer: \", metrics.f1_score(NB_beer_predicted, NB_beer_test_label, average = 'weighted')))\n",
    "print(\"%s %s\" % (\"Weighted f1 score for Outdoors: \", metrics.f1_score(NB_outdoors_predicted, NB_outdoors_test_label, average = 'weighted')))\n",
    "print(\"%s %s\" % (\"Weighted f1 score for Aviation: \", metrics.f1_score(NB_aviation_predicted, NB_aviation_test_label, average = 'weighted')))\n",
    "print(\"%s %s\" % (\"Weighted f1 score for Astronomy: \", metrics.f1_score(NB_astronomy_predicted, NB_astronomy_test_label, average = 'weighted')))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "#Classificaiton Report\n",
    "print(\"Classificaiton Report\")\n",
    "print(metrics.classification_report(NB_test_labels, NB_all_predicted, target_names= ['pets', 'beer','outdoors', 'aviation', 'astronomy']))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "#Confusion Matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(NB_test_labels, NB_all_predicted, labels=['pets', 'beer','outdoors', 'aviation', 'astronomy']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda2\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best score', 0.98272624859181379)\n",
      "('Best parameters', {'vect__ngram_range': (1, 2), 'tfidf__use_idf': True, 'clf-svm__alpha': 0.001})\n"
     ]
    }
   ],
   "source": [
    "# First, we run Support Vector Machine\n",
    "\n",
    "text_clf_svm = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf-svm', SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, n_iter=5, random_state=42))])\n",
    "\n",
    "parameters_svm = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf-svm__alpha': (1e-2, 1e-3)}\n",
    "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, cv=10, n_jobs=-1)\n",
    "gs_clf_model = gs_clf_svm.fit(train_set, train_labels)\n",
    "\n",
    "print(\"Best score\", gs_clf_svm.best_score_)\n",
    "print(\"Best parameters\", gs_clf_svm.best_params_)\n",
    "\n",
    "\n",
    "\n",
    "SVM_pets_predicted = gs_clf_svm.predict(pets_test)\n",
    "SVM_beer_predicted = gs_clf_svm.predict(beer_test)\n",
    "SVM_outdoors_predicted = gs_clf_svm.predict(outdoors_test)\n",
    "SVM_aviation_predicted = gs_clf_svm.predict(aviation_test)\n",
    "SVM_astronomy_predicted = gs_clf_svm.predict(astronomy_test)\n",
    "\n",
    "#print(metrics.classification_report(test_labels, predicted, target_names= ['pets', 'beer', 'astronomy', 'outdoors', 'aviation']))\n",
    "#metrics.confusion_matrix(test_labels, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Pets:  0.99\n",
      "Accuracy score for Beer:  0.99\n",
      "Accuracy score for Outdoors:  0.97\n",
      "Accuracy score for Aviation:  1.0\n",
      "Accuracy score for Astronomy:  0.99\n",
      "\n",
      "\n",
      "\n",
      "Micro f1 score for Pets:  0.99\n",
      "Micro f1 score for Beer:  0.99\n",
      "Micro f1 score for Outdoors:  0.97\n",
      "Micro f1 score for Aviation:  1.0\n",
      "Micro f1 score for Astronomy:  0.99\n",
      "\n",
      "\n",
      "\n",
      "Weighted f1 score for Pets:  0.985025125628\n",
      "Weighted f1 score for Beer:  0.985025125628\n",
      "Weighted f1 score for Outdoors:  0.955228426396\n",
      "Weighted f1 score for Aviation:  1.0\n",
      "Weighted f1 score for Astronomy:  0.985025125628\n",
      "\n",
      "\n",
      "\n",
      "Classificaiton Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       pets       1.00      0.99      0.99       100\n",
      "       beer       0.99      1.00      1.00       100\n",
      "   outdoors       0.99      0.99      0.99       100\n",
      "   aviation       0.98      0.97      0.97       100\n",
      "  astronomy       0.98      0.99      0.99       100\n",
      "\n",
      "avg / total       0.99      0.99      0.99       500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix\n",
      "[[ 99   0   0   1   0]\n",
      " [  0  99   1   0   0]\n",
      " [  2   1  97   0   0]\n",
      " [  0   0   0 100   0]\n",
      " [  0   0   1   0  99]]\n"
     ]
    }
   ],
   "source": [
    "#Evaluate performance of the model on the hold-out set\n",
    "\n",
    "SVM_all_predicted = []\n",
    "SVM_test_labels = []\n",
    "\n",
    "\n",
    "SVM_all_predicted.extend(SVM_astronomy_predicted)\n",
    "SVM_all_predicted.extend(SVM_beer_predicted)\n",
    "SVM_all_predicted.extend(SVM_pets_predicted)\n",
    "SVM_all_predicted.extend(SVM_outdoors_predicted)\n",
    "SVM_all_predicted.extend(SVM_aviation_predicted)\n",
    "\n",
    "SVM_pets_test_label = ['pets']*len(SVM_pets_predicted)\n",
    "SVM_beer_test_label = ['beer']*len(SVM_beer_predicted)\n",
    "SVM_outdoors_test_label = ['outdoors']*len(SVM_outdoors_predicted)\n",
    "SVM_astronomy_test_label = ['astronomy']*len(SVM_astronomy_predicted)\n",
    "SVM_aviation_test_label = ['aviation']*len(SVM_aviation_predicted)\n",
    "\n",
    "SVM_test_labels.extend(SVM_astronomy_test_label)\n",
    "SVM_test_labels.extend(SVM_beer_test_label)\n",
    "SVM_test_labels.extend(SVM_pets_test_label)\n",
    "SVM_test_labels.extend(SVM_outdoors_test_label)\n",
    "SVM_test_labels.extend(SVM_aviation_test_label)\n",
    "\n",
    "\n",
    "#Evaluate performance of the model on the hold-out set\n",
    "\n",
    "#Accuracy\n",
    "print(\"%s %s\" % (\"Accuracy score for Pets: \", metrics.accuracy_score(SVM_pets_predicted, SVM_pets_test_label)))\n",
    "print(\"%s %s\" % (\"Accuracy score for Beer: \", metrics.accuracy_score(SVM_beer_predicted, SVM_beer_test_label)))\n",
    "print(\"%s %s\" % (\"Accuracy score for Outdoors: \", metrics.accuracy_score(SVM_outdoors_predicted, SVM_outdoors_test_label)))\n",
    "print(\"%s %s\" % (\"Accuracy score for Aviation: \", metrics.accuracy_score(SVM_aviation_predicted, SVM_aviation_test_label)))\n",
    "print(\"%s %s\" % (\"Accuracy score for Astronomy: \", metrics.accuracy_score(SVM_astronomy_predicted, SVM_astronomy_test_label)))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "# micro f1 scores\n",
    "print(\"%s %s\" % (\"Micro f1 score for Pets: \", metrics.f1_score(SVM_pets_predicted, SVM_pets_test_label, average = 'micro')))\n",
    "print(\"%s %s\" % (\"Micro f1 score for Beer: \", metrics.f1_score(SVM_beer_predicted, SVM_beer_test_label, average = 'micro')))\n",
    "print(\"%s %s\" % (\"Micro f1 score for Outdoors: \", metrics.f1_score(SVM_outdoors_predicted, SVM_outdoors_test_label, average = 'micro')))\n",
    "print(\"%s %s\" % (\"Micro f1 score for Aviation: \", metrics.f1_score(SVM_aviation_predicted, SVM_aviation_test_label, average = 'micro')))\n",
    "print(\"%s %s\" % (\"Micro f1 score for Astronomy: \", metrics.f1_score(SVM_astronomy_predicted, SVM_astronomy_test_label, average = 'micro')))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "# macro f1 scores\n",
    "print(\"%s %s\" % (\"Weighted f1 score for Pets: \", metrics.f1_score(SVM_pets_predicted, SVM_pets_test_label, average = 'weighted')))\n",
    "print(\"%s %s\" % (\"Weighted f1 score for Beer: \", metrics.f1_score(SVM_beer_predicted, SVM_beer_test_label, average = 'weighted')))\n",
    "print(\"%s %s\" % (\"Weighted f1 score for Outdoors: \", metrics.f1_score(SVM_outdoors_predicted, SVM_outdoors_test_label, average = 'weighted')))\n",
    "print(\"%s %s\" % (\"Weighted f1 score for Aviation: \", metrics.f1_score(SVM_aviation_predicted, SVM_aviation_test_label, average = 'weighted')))\n",
    "print(\"%s %s\" % (\"Weighted f1 score for Astronomy: \", metrics.f1_score(SVM_astronomy_predicted, SVM_astronomy_test_label, average = 'weighted')))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "#Classificaiton Report\n",
    "print(\"Classificaiton Report\")\n",
    "print(metrics.classification_report(SVM_test_labels, SVM_all_predicted, target_names= ['pets', 'beer','outdoors', 'aviation', 'astronomy']))\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "#Confusion Matrix\n",
    "print(\"Confusion Matrix\")\n",
    "print(metrics.confusion_matrix(SVM_test_labels, SVM_all_predicted, labels=['pets', 'beer','outdoors', 'aviation', 'astronomy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename_nb = \"C:/Users/IB/Documents/Academic/Publicis_Assessment/nb_model.txt\"\n",
    "pickle.dump(NB_gs_clf, open(filename_nb, 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have a pair of salomon rocker 2s with z12 bindings on a demo plate. Would it be advantageous for my skiing performance to remove the demo plate and have the bindings directly on the skis? I normally hang out on big mountain shoots and dense tree runs.\n",
      "{\"aviation\": 0.00011917072801573794, \"beer\": 5.9021658565452883e-06, \"astronomy\": 1.2678453637109206e-05, \"pets\": 0.0003468603661065317, \"outdoors\": 0.9995153882863832}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "loaded_model = pickle.load(open(filename_nb, 'rb'))\n",
    "posterior_probabilities = loaded_model.predict_proba([raw_input()])\n",
    "dict_output = {'astronomy': posterior_probabilities[0][0], 'aviation': posterior_probabilities[0][1], 'beer' : posterior_probabilities[0][2],\n",
    "       'outdoors': posterior_probabilities[0][3], 'pets': posterior_probabilities[0][4]}\n",
    "json_output = json.dumps(dict_output)\n",
    "print(json_output)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
